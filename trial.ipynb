{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb07c79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Adidas': ['Logos\\\\Adidas\\\\image.png', 'Logos\\\\Adidas\\\\logo1.png'], 'Nike': ['Logos\\\\Nike\\\\logo1.png', 'Logos\\\\Nike\\\\logo10.png', 'Logos\\\\Nike\\\\logo11.png', 'Logos\\\\Nike\\\\logo12.png', 'Logos\\\\Nike\\\\logo13.jpg', 'Logos\\\\Nike\\\\logo14.png', 'Logos\\\\Nike\\\\logo15.png', 'Logos\\\\Nike\\\\logo16.png', 'Logos\\\\Nike\\\\logo17.png', 'Logos\\\\Nike\\\\logo18.png', 'Logos\\\\Nike\\\\logo19.png', 'Logos\\\\Nike\\\\logo2.png', 'Logos\\\\Nike\\\\logo20.png', 'Logos\\\\Nike\\\\logo3.png', 'Logos\\\\Nike\\\\logo4.png', 'Logos\\\\Nike\\\\logo5.png', 'Logos\\\\Nike\\\\logo6.png', 'Logos\\\\Nike\\\\logo7.png', 'Logos\\\\Nike\\\\logo9.png'], 'Puma': ['Logos\\\\Puma\\\\logo1.png', 'Logos\\\\Puma\\\\logo2.png', 'Logos\\\\Puma\\\\logo3.png', 'Logos\\\\Puma\\\\logo4.png']}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "sift = cv2.SIFT_create(\n",
    "    nOctaveLayers=7,\n",
    "    contrastThreshold=0.01,\n",
    "    sigma=1.414\n",
    ")\n",
    "\n",
    "\n",
    "def load_logos(base_folder: str):\n",
    "    logos_dict = {}\n",
    "    base_path = Path(base_folder)\n",
    "\n",
    "    for brand_folder in base_path.iterdir():\n",
    "        if brand_folder.is_dir():\n",
    "            brand_name = brand_folder.name\n",
    "            logos = [str(file) for file in brand_folder.glob(\"*\") if file.is_file()]\n",
    "            logos_dict[brand_name] = logos\n",
    "\n",
    "    return logos_dict\n",
    "\n",
    "folder = \"Logos\" \n",
    "logos_paths = load_logos(folder)\n",
    "\n",
    "print(logos_paths)\n",
    "descriptores = {}\n",
    "\n",
    "\n",
    "for brand, paths in logos_paths.items():\n",
    "    descriptores[brand] = []\n",
    "    for path in paths:\n",
    "        logo = cv2.imread(path)\n",
    "        \n",
    "        if logo is None:\n",
    "            print(f\"Error loading image: {path}\")\n",
    "            continue\n",
    "\n",
    "        gray_logo = cv2.cvtColor(logo, cv2.COLOR_BGR2GRAY)\n",
    "        kp_logo, des_logo = sift.detectAndCompute(logo, None)\n",
    "        descriptores[brand].append((kp_logo, des_logo))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c89fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b872c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: a1.png\n",
      "============================================================\n",
      "Found 6329 SIFT keypoints\n",
      "RESULT: Puma with 21 good matches ✓\n",
      "\n",
      "============================================================\n",
      "Processing: a2.png\n",
      "============================================================\n",
      "Found 47129 SIFT keypoints\n",
      "RESULT: Adidas with 5 good matches ✓\n",
      "\n",
      "============================================================\n",
      "Processing: a3.png\n",
      "============================================================\n",
      "Found 1962 SIFT keypoints\n",
      "RESULT: Puma with 26 good matches ✓\n",
      "\n",
      "============================================================\n",
      "Processing: a4.png\n",
      "============================================================\n",
      "Found 5164 SIFT keypoints\n",
      "RESULT: Puma with 18 good matches ✓\n",
      "\n",
      "============================================================\n",
      "Processing: adidas_shirt1.png\n",
      "============================================================\n",
      "Found 3703 SIFT keypoints\n",
      "RESULT: Adidas with 37 good matches ✓\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shirt1.png\n",
      "============================================================\n",
      "Found 3160 SIFT keypoints\n",
      "RESULT: Nike with 28 good matches ✓\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shirt2.png\n",
      "============================================================\n",
      "Found 30394 SIFT keypoints\n",
      "RESULT: Nike with 67 good matches ✓\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shirt3.png\n",
      "============================================================\n",
      "Found 6144 SIFT keypoints\n",
      "RESULT: Nike with 23 good matches ✓\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shirt5.png\n",
      "============================================================\n",
      "Found 18009 SIFT keypoints\n",
      "RESULT: Nike with 65 good matches ✓\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shirt6.png\n",
      "============================================================\n",
      "Found 29973 SIFT keypoints\n",
      "RESULT: Nike with 8 good matches ✓\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shoe1.png\n",
      "============================================================\n",
      "Found 7304 SIFT keypoints\n",
      "RESULT: Nike with 8 good matches ✓\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shoe2.png\n",
      "============================================================\n",
      "Found 7641 SIFT keypoints\n",
      "RESULT: Nike with 20 good matches ✓\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Threshold configuration\n",
    "MIN_MATCH_COUNT = 4  # Minimum matches needed for homography\n",
    "BRAND_CONFIDENCE_THRESHOLD = 0  # Minimum good matches to classify as a known brand\n",
    "\n",
    "# Load all cloth images from the Cloth folder\n",
    "cloth_folder = Path(\"Cloth\")\n",
    "cloth_images = list(cloth_folder.glob(\"*\"))\n",
    "\n",
    "# Process each cloth image\n",
    "for cloth_path in cloth_images:\n",
    "    if not cloth_path.is_file():\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {cloth_path.name}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    shirt = cv2.imread(str(cloth_path), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if shirt is None:\n",
    "        print(f\"Error loading image: {cloth_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Compute SIFT features directly on the shirt image\n",
    "    shirt = cv2.bilateralFilter(shirt, 0, 1, 1)\n",
    "    kp_shirt, des_shirt = sift.detectAndCompute(shirt, None)\n",
    "    \n",
    "    if des_shirt is None:\n",
    "        print(\"No descriptors found in shirt\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Found {len(kp_shirt)} SIFT keypoints\")\n",
    "    \n",
    "    best_brand = None\n",
    "    best_match_count = 0\n",
    "    best_matches = None\n",
    "    best_logo_kp = None\n",
    "    best_H = None\n",
    "    best_mask = None\n",
    "    best_logo_index = None\n",
    "    \n",
    "    # Match against all logos from all brands\n",
    "    for brand, logo_data in descriptores.items():\n",
    "        for idx, (kp_logo, des_logo) in enumerate(logo_data):\n",
    "            if des_logo is None:\n",
    "                continue\n",
    "            \n",
    "            # Match with KNN\n",
    "            bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "            knn_matches = bf.knnMatch(des_logo, des_shirt, k=2)\n",
    "            \n",
    "            # Lowe's ratio test\n",
    "            good = []\n",
    "            ratio_thresh = 0.6\n",
    "            \n",
    "            for match_pair in knn_matches:\n",
    "                if len(match_pair) == 2:\n",
    "                    m, n = match_pair\n",
    "                    if m.distance < ratio_thresh * n.distance:\n",
    "                        good.append(m)\n",
    "            \n",
    "            # Apply RANSAC to filter outliers if we have enough matches\n",
    "            inlier_count = 0\n",
    "            H = None\n",
    "            mask = None\n",
    "            \n",
    "            if len(good) >= MIN_MATCH_COUNT:\n",
    "                src_pts = np.float32([kp_logo[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "                dst_pts = np.float32([kp_shirt[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "                H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "                \n",
    "                # Count only inliers (matches that fit the homography model)\n",
    "                if mask is not None:\n",
    "                    inlier_count = mask.sum()\n",
    "            \n",
    "            # Check if this is the best match so far (using inlier count)\n",
    "            if inlier_count > best_match_count:\n",
    "                best_match_count = inlier_count\n",
    "                best_brand = brand\n",
    "                best_matches = good\n",
    "                best_logo_kp = kp_logo\n",
    "                best_logo_index = idx\n",
    "                best_H = H\n",
    "                best_mask = mask\n",
    "    \n",
    "    # Determine if it's a known brand or unknown based on threshold\n",
    "    if best_match_count < BRAND_CONFIDENCE_THRESHOLD:\n",
    "        print(f\"RESULT: UNKNOWN BRAND (only {best_match_count} matches found, threshold is {BRAND_CONFIDENCE_THRESHOLD})\")\n",
    "        is_known_brand = False\n",
    "    else:\n",
    "        print(f\"RESULT: {best_brand} with {best_match_count} good matches ✓\")\n",
    "        is_known_brand = True\n",
    "    \n",
    "    # Display results for this cloth\n",
    "    if best_matches and best_match_count >= MIN_MATCH_COUNT and is_known_brand:\n",
    "        # Load the best matching logo for visualization\n",
    "        logo_path = logos_paths[best_brand][best_logo_index]\n",
    "        logo = cv2.imread(logo_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        matchesMask = best_mask.ravel().tolist() if best_mask is not None else None\n",
    "        \n",
    "        # Draw matches\n",
    "        result = cv2.drawMatches(\n",
    "            logo, best_logo_kp,\n",
    "            shirt, kp_shirt,\n",
    "            best_matches, None,\n",
    "            matchesMask=matchesMask,\n",
    "            flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "        )\n",
    "        \n",
    "        cv2.namedWindow(f\"Matches - {cloth_path.name}\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(f\"Matches - {cloth_path.name}\", result)\n",
    "        cv2.resizeWindow(f\"Matches - {cloth_path.name}\", 1000, 1000)\n",
    "        \n",
    "        # Draw bounding box on original shirt image\n",
    "        if best_H is not None:\n",
    "            h, w = logo.shape\n",
    "            logo_corners = np.float32([\n",
    "                [0, 0],\n",
    "                [0, h - 1],\n",
    "                [w - 1, h - 1],\n",
    "                [w - 1, 0]\n",
    "            ]).reshape(-1, 1, 2)\n",
    "            \n",
    "            projected_corners = cv2.perspectiveTransform(logo_corners, best_H)\n",
    "            \n",
    "            shirt_color = cv2.cvtColor(shirt, cv2.COLOR_GRAY2BGR)\n",
    "            shirt_with_box = cv2.polylines(\n",
    "                shirt_color,\n",
    "                [np.int32(projected_corners)],\n",
    "                isClosed=True,\n",
    "                color=(0, 255, 0),\n",
    "                thickness=3,\n",
    "                lineType=cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # Add brand label on the image\n",
    "            cv2.putText(\n",
    "                shirt_with_box,\n",
    "                f\"Brand: {best_brand}\",\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            cv2.namedWindow(f\"Detection - {cloth_path.name}\", cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow(f\"Detection - {cloth_path.name}\", shirt_with_box)\n",
    "            cv2.resizeWindow(f\"Detection - {cloth_path.name}\", 800, 800)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    elif not is_known_brand:\n",
    "        print(f\"Skipping visualization - classified as UNKNOWN BRAND\")\n",
    "    else:\n",
    "        print(f\"Not enough matches found for detection visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0444169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: a1.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 2 suspected logo regions\n",
      "\n",
      "Press any key to continue with SIFT matching...\n",
      "\n",
      "  Analyzing region 1/2 at (159, 298, 221, 124)\n",
      "    Found 176 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 2/2 at (25, 0, 453, 697)\n",
      "    Found 421 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Puma with 16 good matches ✓\n",
      "Logo detected in region: (159, 298, 221, 124)\n",
      "\n",
      "============================================================\n",
      "Processing: a2.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 1 suspected logo regions\n",
      "\n",
      "Press any key to continue with SIFT matching...\n",
      "\n",
      "  Analyzing region 1/1 at (707, 1757, 111, 243)\n",
      "    Found 13 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Nike with 4 good matches ✓\n",
      "Logo detected in region: (707, 1757, 111, 243)\n",
      "\n",
      "============================================================\n",
      "Processing: a3.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 8 suspected logo regions\n",
      "\n",
      "Press any key to continue with SIFT matching...\n",
      "\n",
      "  Analyzing region 1/8 at (689, 845, 39, 50)\n",
      "    Found 12 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 2/8 at (161, 424, 60, 127)\n",
      "    Found 2 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 3/8 at (690, 423, 86, 83)\n",
      "    Found 20 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 4/8 at (452, 252, 181, 154)\n",
      "    Found 138 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 5/8 at (244, 247, 319, 321)\n",
      "    Found 256 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 6/8 at (434, 62, 66, 47)\n",
      "    Found 25 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 7/8 at (505, 0, 90, 138)\n",
      "    Found 4 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 8/8 at (0, 0, 373, 501)\n",
      "    Found 115 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Nike with 115 good matches ✓\n",
      "Logo detected in region: (0, 0, 373, 501)\n",
      "\n",
      "============================================================\n",
      "Processing: a4.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 5 suspected logo regions\n",
      "\n",
      "Press any key to continue with SIFT matching...\n",
      "\n",
      "  Analyzing region 1/5 at (0, 473, 110, 81)\n",
      "    Found 48 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 2/5 at (429, 236, 160, 267)\n",
      "    Found 130 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 3/5 at (150, 103, 188, 261)\n",
      "    Found 150 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 4/5 at (409, 45, 191, 112)\n",
      "    Found 104 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 5/5 at (0, 0, 600, 554)\n",
      "    Found 907 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Puma with 23 good matches ✓\n",
      "Logo detected in region: (150, 103, 188, 261)\n",
      "\n",
      "============================================================\n",
      "Processing: adidas_shirt1.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 5 suspected logo regions\n",
      "\n",
      "Press any key to continue with SIFT matching...\n",
      "\n",
      "  Analyzing region 1/5 at (286, 1346, 56, 52)\n",
      "    Found 3 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 2/5 at (47, 925, 75, 184)\n",
      "    Found 17 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 3/5 at (99, 551, 88, 89)\n",
      "    Found 6 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 4/5 at (148, 492, 123, 146)\n",
      "    Found 10 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 5/5 at (216, 435, 143, 202)\n",
      "    Found 14 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Adidas with 20 good matches ✓\n",
      "Logo detected in region: (148, 492, 123, 146)\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shirt1.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 1 suspected logo regions\n",
      "\n",
      "Press any key to continue with SIFT matching...\n",
      "\n",
      "  Analyzing region 1/1 at (923, 979, 225, 621)\n",
      "    Found 52 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Nike with 17 good matches ✓\n",
      "Logo detected in region: (923, 979, 225, 621)\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shirt2.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 3 suspected logo regions\n",
      "\n",
      "Press any key to continue with SIFT matching...\n",
      "\n",
      "  Analyzing region 1/3 at (277, 1995, 70, 165)\n",
      "    Found 9 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 2/3 at (207, 1936, 69, 46)\n",
      "    Found 2 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 3/3 at (760, 1455, 154, 437)\n",
      "    Found 91 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Nike with 27 good matches ✓\n",
      "Logo detected in region: (277, 1995, 70, 165)\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shirt3.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 14 suspected logo regions\n",
      "\n",
      "Press any key to continue with SIFT matching...\n",
      "\n",
      "  Analyzing region 1/14 at (694, 1283, 51, 55)\n",
      "    Found 7 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 2/14 at (748, 1168, 68, 170)\n",
      "    Found 6 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 3/14 at (334, 1031, 133, 307)\n",
      "    Found 9 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 4/14 at (366, 578, 329, 212)\n",
      "    Found 103 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 5/14 at (666, 402, 189, 315)\n",
      "    Found 52 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 6/14 at (331, 290, 103, 133)\n",
      "    Found 11 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 7/14 at (364, 251, 66, 69)\n",
      "    Found 6 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 8/14 at (504, 198, 119, 127)\n",
      "    Found 47 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 9/14 at (459, 153, 66, 156)\n",
      "    Found 14 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 10/14 at (506, 132, 69, 58)\n",
      "    Found 20 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 11/14 at (429, 119, 60, 104)\n",
      "    Found 13 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 12/14 at (527, 102, 72, 44)\n",
      "    Found 2 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 13/14 at (363, 60, 326, 436)\n",
      "    Found 307 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 14/14 at (272, 0, 395, 378)\n",
      "    Found 423 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Nike with 21 good matches ✓\n",
      "Logo detected in region: (366, 578, 329, 212)\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shirt5.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 23 suspected logo regions\n",
      "\n",
      "Press any key to continue with SIFT matching...\n",
      "\n",
      "  Analyzing region 1/23 at (1237, 2287, 110, 53)\n",
      "    Found 1 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 2/23 at (685, 1893, 332, 447)\n",
      "    Found 20 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 3/23 at (828, 1870, 58, 95)\n",
      "    Found 2 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 4/23 at (1389, 1765, 50, 99)\n",
      "    Found 8 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 5/23 at (958, 1728, 449, 612)\n",
      "    Found 89 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 6/23 at (647, 1602, 188, 300)\n",
      "    Found 12 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 7/23 at (684, 1587, 45, 53)\n",
      "    Found 3 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 8/23 at (333, 1138, 353, 852)\n",
      "    Found 79 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 9/23 at (1162, 987, 234, 132)\n",
      "    Found 7 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 10/23 at (916, 753, 157, 88)\n",
      "    Found 4 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 11/23 at (521, 617, 279, 525)\n",
      "    Found 56 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 12/23 at (673, 530, 254, 138)\n",
      "    Found 65 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 13/23 at (787, 510, 64, 45)\n",
      "    Found 8 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 14/23 at (740, 504, 160, 98)\n",
      "    Found 42 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 15/23 at (577, 489, 48, 57)\n",
      "    Found 2 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 16/23 at (738, 409, 117, 115)\n",
      "    Found 23 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 17/23 at (758, 403, 55, 84)\n",
      "    Found 9 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 18/23 at (642, 373, 79, 77)\n",
      "    Found 4 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 19/23 at (576, 336, 91, 55)\n",
      "    No descriptors found in region 19\n",
      "\n",
      "  Analyzing region 20/23 at (769, 274, 130, 121)\n",
      "    Found 57 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 21/23 at (755, 214, 131, 130)\n",
      "    Found 53 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 22/23 at (704, 167, 45, 52)\n",
      "    Found 3 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 23/23 at (810, 102, 733, 1811)\n",
      "    Found 467 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Nike with 45 good matches ✓\n",
      "Logo detected in region: (521, 617, 279, 525)\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shirt6.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 2 suspected logo regions\n",
      "\n",
      "Press any key to continue with SIFT matching...\n",
      "\n",
      "  Analyzing region 1/2 at (808, 901, 145, 183)\n",
      "    Found 35 SIFT keypoints in this region\n",
      "\n",
      "  Analyzing region 2/2 at (906, 900, 93, 181)\n",
      "    Found 22 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Nike with 46 good matches ✓\n",
      "Logo detected in region: (808, 901, 145, 183)\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shoe1.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 0 suspected logo regions\n",
      "No logo regions detected - trying full image instead\n",
      "\n",
      "  Analyzing region 1/1 at (0, 0, 1070, 1338)\n",
      "    Found 1689 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Nike with 13 good matches ✓\n",
      "Logo detected in region: (0, 0, 1070, 1338)\n",
      "\n",
      "============================================================\n",
      "Processing: nike_shoe2.png\n",
      "============================================================\n",
      "Extracting logo regions...\n",
      "Found 0 suspected logo regions\n",
      "No logo regions detected - trying full image instead\n",
      "\n",
      "  Analyzing region 1/1 at (0, 0, 1070, 1338)\n",
      "    Found 2446 SIFT keypoints in this region\n",
      "\n",
      "RESULT: Nike with 8 good matches ✓\n",
      "Logo detected in region: (0, 0, 1070, 1338)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Threshold configuration\n",
    "MIN_MATCH_COUNT = 4  # Minimum matches needed for homography\n",
    "BRAND_CONFIDENCE_THRESHOLD = 0  # Minimum good matches to classify as a known brand\n",
    "\n",
    "# Contour extraction parameters\n",
    "MIN_CONTOUR_AREA = 500  # Minimum area for a contour to be considered\n",
    "MAX_CONTOUR_AREA = 50000  # Maximum area for a contour to be considered\n",
    "MIN_ASPECT_RATIO = 0.3  # Minimum width/height ratio\n",
    "MAX_ASPECT_RATIO = 3.0  # Maximum width/height ratio\n",
    "\n",
    "def extract_logo_regions(image):\n",
    "    \"\"\"\n",
    "    Extract suspected logo regions using edge detection and contour analysis.\n",
    "    Returns list of (x, y, w, h, roi) tuples for each suspected logo region.\n",
    "    \"\"\"\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    # Morphological operations to close gaps in edges\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "    dilated = cv2.dilate(closed, kernel, iterations=2)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    logo_regions = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        # Calculate contour properties\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        # Filter by area\n",
    "        if area < MIN_CONTOUR_AREA or area > MAX_CONTOUR_AREA:\n",
    "            continue\n",
    "        \n",
    "        # Get bounding rectangle\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Filter by aspect ratio (reject very elongated shapes)\n",
    "        aspect_ratio = w / float(h)\n",
    "        if aspect_ratio < MIN_ASPECT_RATIO or aspect_ratio > MAX_ASPECT_RATIO:\n",
    "            continue\n",
    "        \n",
    "        # Add padding around the region\n",
    "        padding = 10\n",
    "        x_padded = max(0, x - padding)\n",
    "        y_padded = max(0, y - padding)\n",
    "        w_padded = min(image.shape[1] - x_padded, w + 2 * padding)\n",
    "        h_padded = min(image.shape[0] - y_padded, h + 2 * padding)\n",
    "        \n",
    "        # Extract the region of interest\n",
    "        roi = image[y_padded:y_padded + h_padded, x_padded:x_padded + w_padded]\n",
    "        \n",
    "        if roi.size > 0:\n",
    "            logo_regions.append((x_padded, y_padded, w_padded, h_padded, roi))\n",
    "    \n",
    "    return logo_regions\n",
    "\n",
    "\n",
    "# Load all cloth images from the Cloth folder\n",
    "cloth_folder = Path(\"Cloth\")\n",
    "cloth_images = list(cloth_folder.glob(\"*\"))\n",
    "\n",
    "# Load logo descriptors (assuming these are pre-computed)\n",
    "# descriptores = {...}  # Your existing logo descriptors dictionary\n",
    "# logos_paths = {...}   # Your existing logo paths dictionary\n",
    "\n",
    "# Process each cloth image\n",
    "for cloth_path in cloth_images:\n",
    "    if not cloth_path.is_file():\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {cloth_path.name}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    shirt = cv2.imread(str(cloth_path), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if shirt is None:\n",
    "        print(f\"Error loading image: {cloth_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Extract suspected logo regions using edge detection and contours\n",
    "    print(\"Extracting logo regions...\")\n",
    "    logo_regions = extract_logo_regions(shirt)\n",
    "    print(f\"Found {len(logo_regions)} suspected logo regions\")\n",
    "    \n",
    "    # Visualize the extracted regions\n",
    "    if len(logo_regions) > 0:\n",
    "        # Create visualization of edge detection and contours\n",
    "        shirt_color = cv2.cvtColor(shirt, cv2.COLOR_GRAY2BGR)\n",
    "        blurred = cv2.GaussianBlur(shirt, (5, 5), 0)\n",
    "        edges = cv2.Canny(blurred, 50, 150)\n",
    "        edges_color = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # Draw rectangles on detected regions\n",
    "        shirt_with_regions = shirt_color.copy()\n",
    "        for idx, (x, y, w, h, roi) in enumerate(logo_regions):\n",
    "            cv2.rectangle(shirt_with_regions, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "            cv2.putText(shirt_with_regions, f\"R{idx+1}\", (x, y-5), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        \n",
    "        # Show edge detection result\n",
    "        cv2.namedWindow(f\"Edges - {cloth_path.name}\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(f\"Edges - {cloth_path.name}\", edges_color)\n",
    "        cv2.resizeWindow(f\"Edges - {cloth_path.name}\", 800, 800)\n",
    "        \n",
    "        # Show detected regions on original image\n",
    "        cv2.namedWindow(f\"Detected Regions - {cloth_path.name}\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(f\"Detected Regions - {cloth_path.name}\", shirt_with_regions)\n",
    "        cv2.resizeWindow(f\"Detected Regions - {cloth_path.name}\", 800, 800)\n",
    "        \n",
    "        # Show each extracted ROI separately\n",
    "        for idx, (x, y, w, h, roi) in enumerate(logo_regions):\n",
    "            cv2.namedWindow(f\"ROI {idx+1} - {cloth_path.name}\", cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow(f\"ROI {idx+1} - {cloth_path.name}\", roi)\n",
    "            cv2.resizeWindow(f\"ROI {idx+1} - {cloth_path.name}\", 300, 300)\n",
    "        \n",
    "        print(\"\\nPress any key to continue with SIFT matching...\")\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    if len(logo_regions) == 0:\n",
    "        print(\"No logo regions detected - trying full image instead\")\n",
    "        logo_regions = [(0, 0, shirt.shape[1], shirt.shape[0], shirt)]\n",
    "    \n",
    "    best_brand = None\n",
    "    best_match_count = 0\n",
    "    best_matches = None\n",
    "    best_logo_kp = None\n",
    "    best_H = None\n",
    "    best_mask = None\n",
    "    best_logo_index = None\n",
    "    best_region = None\n",
    "    best_region_coords = None\n",
    "    best_roi_kp = None\n",
    "    \n",
    "    # Process each suspected logo region\n",
    "    for region_idx, (x, y, w, h, roi) in enumerate(logo_regions):\n",
    "        print(f\"\\n  Analyzing region {region_idx + 1}/{len(logo_regions)} at ({x}, {y}, {w}, {h})\")\n",
    "        \n",
    "        # Compute SIFT features on this region\n",
    "        kp_roi, des_roi = sift.detectAndCompute(roi, None)\n",
    "        \n",
    "        if des_roi is None:\n",
    "            print(f\"    No descriptors found in region {region_idx + 1}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"    Found {len(kp_roi)} SIFT keypoints in this region\")\n",
    "        \n",
    "        # Match against all logos from all brands\n",
    "        for brand, logo_data in descriptores.items():\n",
    "            for idx, (kp_logo, des_logo) in enumerate(logo_data):\n",
    "                if des_logo is None:\n",
    "                    continue\n",
    "                \n",
    "                # Match with KNN\n",
    "                bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "                knn_matches = bf.knnMatch(des_logo, des_roi, k=2)\n",
    "                \n",
    "                # Lowe's ratio test\n",
    "                good = []\n",
    "                ratio_thresh = 0.6\n",
    "                \n",
    "                for match_pair in knn_matches:\n",
    "                    if len(match_pair) == 2:\n",
    "                        m, n = match_pair\n",
    "                        if m.distance < ratio_thresh * n.distance:\n",
    "                            good.append(m)\n",
    "                \n",
    "                # Apply RANSAC to filter outliers if we have enough matches\n",
    "                inlier_count = 0\n",
    "                H = None\n",
    "                mask = None\n",
    "                \n",
    "                if len(good) >= MIN_MATCH_COUNT:\n",
    "                    src_pts = np.float32([kp_logo[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "                    dst_pts = np.float32([kp_roi[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "                    \n",
    "                    # Adjust destination points to global coordinates\n",
    "                    dst_pts_global = dst_pts.copy()\n",
    "                    dst_pts_global[:, 0, 0] += x\n",
    "                    dst_pts_global[:, 0, 1] += y\n",
    "                    \n",
    "                    H, mask = cv2.findHomography(src_pts, dst_pts_global, cv2.RANSAC, 5.0)\n",
    "                    \n",
    "                    # Count only inliers (matches that fit the homography model)\n",
    "                    if mask is not None:\n",
    "                        inlier_count = int(mask.sum())\n",
    "                \n",
    "                # Check if this is the best match so far (using inlier count)\n",
    "                if inlier_count > best_match_count:\n",
    "                    best_match_count = inlier_count\n",
    "                    best_brand = brand\n",
    "                    best_matches = good\n",
    "                    best_logo_kp = kp_logo\n",
    "                    best_logo_index = idx\n",
    "                    best_region = roi\n",
    "                    best_region_coords = (x, y, w, h)\n",
    "                    best_H = H\n",
    "                    best_mask = mask\n",
    "                    \n",
    "                    # Store keypoints in global coordinates for visualization\n",
    "                    kp_roi_global = []\n",
    "                    for kp in kp_roi:\n",
    "                        kp_copy = cv2.KeyPoint(kp.pt[0] + x, kp.pt[1] + y, kp.size, \n",
    "                                               kp.angle, kp.response, kp.octave, kp.class_id)\n",
    "                        kp_roi_global.append(kp_copy)\n",
    "                    best_roi_kp = kp_roi_global\n",
    "    \n",
    "    # Determine if it's a known brand or unknown based on threshold\n",
    "    if best_match_count < BRAND_CONFIDENCE_THRESHOLD:\n",
    "        print(f\"\\nRESULT: UNKNOWN BRAND (only {best_match_count} matches found, threshold is {BRAND_CONFIDENCE_THRESHOLD})\")\n",
    "        is_known_brand = False\n",
    "    else:\n",
    "        print(f\"\\nRESULT: {best_brand} with {best_match_count} good matches ✓\")\n",
    "        if best_region_coords:\n",
    "            print(f\"Logo detected in region: {best_region_coords}\")\n",
    "        is_known_brand = True\n",
    "    \n",
    "    # Display results for this cloth\n",
    "    if best_matches and best_match_count >= MIN_MATCH_COUNT and is_known_brand:\n",
    "        # Load the best matching logo for visualization\n",
    "        logo_path = logos_paths[best_brand][best_logo_index]\n",
    "        logo = cv2.imread(logo_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        matchesMask = best_mask.ravel().tolist() if best_mask is not None else None\n",
    "        \n",
    "        # Draw matches\n",
    "        result = cv2.drawMatches(\n",
    "            logo, best_logo_kp,\n",
    "            shirt, best_roi_kp,\n",
    "            best_matches, None,\n",
    "            matchesMask=matchesMask,\n",
    "            flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "        )\n",
    "        \n",
    "        cv2.namedWindow(f\"Matches - {cloth_path.name}\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(f\"Matches - {cloth_path.name}\", result)\n",
    "        cv2.resizeWindow(f\"Matches - {cloth_path.name}\", 1000, 1000)\n",
    "        \n",
    "        # Draw bounding box on original shirt image\n",
    "        if best_H is not None:\n",
    "            h_logo, w_logo = logo.shape\n",
    "            logo_corners = np.float32([\n",
    "                [0, 0],\n",
    "                [0, h_logo - 1],\n",
    "                [w_logo - 1, h_logo - 1],\n",
    "                [w_logo - 1, 0]\n",
    "            ]).reshape(-1, 1, 2)\n",
    "            \n",
    "            projected_corners = cv2.perspectiveTransform(logo_corners, best_H)\n",
    "            \n",
    "            shirt_color = cv2.cvtColor(shirt, cv2.COLOR_GRAY2BGR)\n",
    "            \n",
    "            # Draw the detected region rectangle (in blue)\n",
    "            if best_region_coords:\n",
    "                x, y, w, h = best_region_coords\n",
    "                cv2.rectangle(shirt_color, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            \n",
    "            # Draw the logo detection bounding box (in green)\n",
    "            shirt_with_box = cv2.polylines(\n",
    "                shirt_color,\n",
    "                [np.int32(projected_corners)],\n",
    "                isClosed=True,\n",
    "                color=(0, 255, 0),\n",
    "                thickness=3,\n",
    "                lineType=cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # Add brand label on the image\n",
    "            cv2.putText(\n",
    "                shirt_with_box,\n",
    "                f\"Brand: {best_brand}\",\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            cv2.namedWindow(f\"Detection - {cloth_path.name}\", cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow(f\"Detection - {cloth_path.name}\", shirt_with_box)\n",
    "            cv2.resizeWindow(f\"Detection - {cloth_path.name}\", 800, 800)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    elif not is_known_brand:\n",
    "        print(f\"Skipping visualization - classified as UNKNOWN BRAND\")\n",
    "    else:\n",
    "        print(f\"Not enough matches found for detection visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3df594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Threshold configuration\n",
    "MIN_MATCH_COUNT = 4  # Minimum matches needed for homography\n",
    "BRAND_CONFIDENCE_THRESHOLD = 0  # Minimum good matches to classify as a known brand\n",
    "\n",
    "def preprocess_image_with_segmentation(image):\n",
    "    \"\"\"\n",
    "    Preprocess image using color segmentation and Canny edge detection.\n",
    "    Returns a processed image suitable for SIFT feature detection.\n",
    "    \"\"\"\n",
    "    # Convert to color for segmentation\n",
    "    if len(image.shape) == 2:\n",
    "        image_color = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        image_color = image.copy()\n",
    "    \n",
    "    # Apply bilateral filter to reduce noise while preserving edges\n",
    "    #filtered = cv2.bilateralFilter(image_color, 9, 75, 75)\n",
    "    filtered = image_color\n",
    "    # Convert to different color spaces for better segmentation\n",
    "    hsv = cv2.cvtColor(filtered, cv2.COLOR_BGR2HSV)\n",
    "    lab = cv2.cvtColor(filtered, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Perform K-means clustering for color segmentation\n",
    "    # Reshape image to be a list of pixels\n",
    "    pixels = filtered.reshape((-1, 3))\n",
    "    pixels = np.float32(pixels)\n",
    "    \n",
    "    # Define criteria and apply K-means\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    k = 5  # Number of clusters\n",
    "    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_PP_CENTERS)\n",
    "    \n",
    "    # Convert back to 8-bit values\n",
    "    centers = np.uint8(centers)\n",
    "    segmented = centers[labels.flatten()]\n",
    "    segmented_image = segmented.reshape(image_color.shape)\n",
    "    \n",
    "    # Convert segmented image to grayscale for edge detection\n",
    "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Canny edge detection on the segmented image\n",
    "    edges = cv2.Canny(segmented_gray, 50, 150)\n",
    "    \n",
    "    # Dilate edges slightly to make them more prominent\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    edges_dilated = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Create the final processed image\n",
    "    # For each edge pixel in the Canny output, keep the corresponding pixel from segmented image\n",
    "    processed = segmented_gray.copy()\n",
    "    \n",
    "    # Enhance edge regions by blending\n",
    "    # Where there's an edge, use the original segmented value\n",
    "    # Where there's no edge, slightly blur to reduce noise\n",
    "    mask_edges = edges_dilated > 0\n",
    "    \n",
    "    # Apply Gaussian blur to non-edge regions\n",
    "    blurred = cv2.GaussianBlur(segmented_gray, (5, 5), 0)\n",
    "    processed[~mask_edges] = blurred[~mask_edges]\n",
    "    \n",
    "    # Enhance contrast\n",
    "    processed = cv2.equalizeHist(processed)\n",
    "    \n",
    "    # Combine edge information with segmented image\n",
    "    # Give more weight to edge pixels\n",
    "    alpha = 0.5\n",
    "    final = cv2.addWeighted(processed, alpha, edges_dilated, 1 - alpha, 0)\n",
    "    \n",
    "    return final, segmented_image, edges\n",
    "\n",
    "\n",
    "# Load all cloth images from the Cloth folder\n",
    "cloth_folder = Path(\"Cloth\")\n",
    "cloth_images = list(cloth_folder.glob(\"*\"))\n",
    "\n",
    "# Process each cloth image\n",
    "for cloth_path in cloth_images:\n",
    "    if not cloth_path.is_file():\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {cloth_path.name}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Load image in color first\n",
    "    shirt_color = cv2.imread(str(cloth_path))\n",
    "    \n",
    "    if shirt_color is None:\n",
    "        print(f\"Error loading image: {cloth_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Preprocess with segmentation and edge detection\n",
    "    print(\"Applying color segmentation and edge detection...\")\n",
    "    processed_shirt, segmented, edges = preprocess_image_with_segmentation(shirt_color)\n",
    "    \n",
    "    # Compute SIFT features on the processed image\n",
    "    kp_shirt, des_shirt = sift.detectAndCompute(processed_shirt, None)\n",
    "    \n",
    "    if des_shirt is None:\n",
    "        print(\"No descriptors found in shirt\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Found {len(kp_shirt)} SIFT keypoints\")\n",
    "    \n",
    "    best_brand = None\n",
    "    best_match_count = 0\n",
    "    best_matches = None\n",
    "    best_logo_kp = None\n",
    "    best_H = None\n",
    "    best_mask = None\n",
    "    best_logo_index = None\n",
    "    \n",
    "    # Match against all logos from all brands\n",
    "    for brand, logo_data in descriptores.items():\n",
    "        for idx, (kp_logo, des_logo) in enumerate(logo_data):\n",
    "            if des_logo is None:\n",
    "                continue\n",
    "            \n",
    "            # Match with KNN\n",
    "            bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "            knn_matches = bf.knnMatch(des_logo, des_shirt, k=2)\n",
    "            \n",
    "            # Lowe's ratio test\n",
    "            good = []\n",
    "            ratio_thresh = 0.6\n",
    "            \n",
    "            for match_pair in knn_matches:\n",
    "                if len(match_pair) == 2:\n",
    "                    m, n = match_pair\n",
    "                    if m.distance < ratio_thresh * n.distance:\n",
    "                        good.append(m)\n",
    "            \n",
    "            # Apply RANSAC to filter outliers if we have enough matches\n",
    "            inlier_count = 0\n",
    "            H = None\n",
    "            mask = None\n",
    "            \n",
    "            if len(good) >= MIN_MATCH_COUNT:\n",
    "                src_pts = np.float32([kp_logo[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "                dst_pts = np.float32([kp_shirt[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "                H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "                \n",
    "                # Count only inliers (matches that fit the homography model)\n",
    "                if mask is not None:\n",
    "                    inlier_count = int(mask.sum())\n",
    "            \n",
    "            # Check if this is the best match so far (using inlier count)\n",
    "            if inlier_count > best_match_count:\n",
    "                best_match_count = inlier_count\n",
    "                best_brand = brand\n",
    "                best_matches = good\n",
    "                best_logo_kp = kp_logo\n",
    "                best_logo_index = idx\n",
    "                best_H = H\n",
    "                best_mask = mask\n",
    "    \n",
    "    # Determine if it's a known brand or unknown based on threshold\n",
    "    if best_match_count < BRAND_CONFIDENCE_THRESHOLD:\n",
    "        print(f\"RESULT: UNKNOWN BRAND (only {best_match_count} matches found, threshold is {BRAND_CONFIDENCE_THRESHOLD})\")\n",
    "        is_known_brand = False\n",
    "    else:\n",
    "        print(f\"RESULT: {best_brand} with {best_match_count} good matches ✓\")\n",
    "        is_known_brand = True\n",
    "    \n",
    "    # Display preprocessing results\n",
    "    preprocessing_stack = np.hstack([\n",
    "        cv2.cvtColor(cv2.resize(cv2.cvtColor(shirt_color, cv2.COLOR_BGR2GRAY), (300, 300)), cv2.COLOR_GRAY2BGR),\n",
    "        cv2.resize(segmented, (300, 300)),\n",
    "        cv2.cvtColor(cv2.resize(edges, (300, 300)), cv2.COLOR_GRAY2BGR),\n",
    "        cv2.cvtColor(cv2.resize(processed_shirt, (300, 300)), cv2.COLOR_GRAY2BGR)\n",
    "    ])\n",
    "    \n",
    "    cv2.namedWindow(f\"Preprocessing - {cloth_path.name}\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(f\"Preprocessing - {cloth_path.name}\", preprocessing_stack)\n",
    "    cv2.resizeWindow(f\"Preprocessing - {cloth_path.name}\", 1200, 300)\n",
    "    \n",
    "    # Add labels to the preprocessing display\n",
    "    labels = [\"Original\", \"Segmented\", \"Edges\", \"Processed\"]\n",
    "    for i, label in enumerate(labels):\n",
    "        cv2.putText(preprocessing_stack, label, (i * 300 + 10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display results for this cloth\n",
    "    if best_matches and best_match_count >= MIN_MATCH_COUNT and is_known_brand:\n",
    "        # Load the best matching logo for visualization\n",
    "        logo_path = logos_paths[best_brand][best_logo_index]\n",
    "        logo = cv2.imread(logo_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        matchesMask = best_mask.ravel().tolist() if best_mask is not None else None\n",
    "        \n",
    "        # Draw matches\n",
    "        result = cv2.drawMatches(\n",
    "            logo, best_logo_kp,\n",
    "            processed_shirt, kp_shirt,\n",
    "            best_matches, None,\n",
    "            matchesMask=matchesMask,\n",
    "            flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",
    "        )\n",
    "        \n",
    "        cv2.namedWindow(f\"Matches - {cloth_path.name}\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(f\"Matches - {cloth_path.name}\", result)\n",
    "        cv2.resizeWindow(f\"Matches - {cloth_path.name}\", 1000, 1000)\n",
    "        \n",
    "        # Draw bounding box on original shirt image\n",
    "        if best_H is not None:\n",
    "            h, w = logo.shape\n",
    "            logo_corners = np.float32([\n",
    "                [0, 0],\n",
    "                [0, h - 1],\n",
    "                [w - 1, h - 1],\n",
    "                [w - 1, 0]\n",
    "            ]).reshape(-1, 1, 2)\n",
    "            \n",
    "            projected_corners = cv2.perspectiveTransform(logo_corners, best_H)\n",
    "            \n",
    "            shirt_with_box = cv2.polylines(\n",
    "                shirt_color.copy(),\n",
    "                [np.int32(projected_corners)],\n",
    "                isClosed=True,\n",
    "                color=(0, 255, 0),\n",
    "                thickness=3,\n",
    "                lineType=cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # Add brand label on the image\n",
    "            cv2.putText(\n",
    "                shirt_with_box,\n",
    "                f\"Brand: {best_brand}\",\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            cv2.namedWindow(f\"Detection - {cloth_path.name}\", cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow(f\"Detection - {cloth_path.name}\", shirt_with_box)\n",
    "            cv2.resizeWindow(f\"Detection - {cloth_path.name}\", 800, 800)\n",
    "        \n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    elif not is_known_brand:\n",
    "        print(f\"Skipping visualization - classified as UNKNOWN BRAND\")\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(f\"Not enough matches found for detection visualization\")\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
